
[0] Code Region

Iterations:        100
Instructions:      2500
Total Cycles:      7224
Dispatch Width:    4
IPC:               0.35
Block RThroughput: 12.0


Instruction Info:
[1]: #uOps
[2]: Latency
[3]: RThroughput
[4]: MayLoad
[5]: MayStore
[6]: HasSideEffects (U)

[1]    [2]    [3]    [4]    [5]    [6]    Instructions:
 1      8     0.50    *                   vmovsd	8(%r12,%r11), %xmm2
 1      1     0.25                        incq	%r15
 1      10    1.00    *                   vaddsd	16(%r12,%r13), %xmm2, %xmm3
 1      10    1.00    *                   vaddsd	8(%r12,%r10), %xmm3, %xmm4
 1      3     1.00                        vaddsd	%xmm1, %xmm4, %xmm1
 1      3     0.50                        vmulsd	%xmm1, %xmm0, %xmm5
 1      1     0.50           *            vmovsd	%xmm5, 8(%r12,%r13)
 1      10    1.00    *                   vaddsd	16(%r12,%r11), %xmm5, %xmm6
 1      10    1.00    *                   vaddsd	24(%r12,%r13), %xmm6, %xmm7
 1      10    1.00    *                   vaddsd	16(%r12,%r10), %xmm7, %xmm8
 1      3     0.50                        vmulsd	%xmm8, %xmm0, %xmm9
 1      1     0.50           *            vmovsd	%xmm9, 16(%r12,%r13)
 1      10    1.00    *                   vaddsd	24(%r12,%r11), %xmm9, %xmm10
 1      10    1.00    *                   vaddsd	32(%r12,%r13), %xmm10, %xmm11
 1      10    1.00    *                   vaddsd	24(%r12,%r10), %xmm11, %xmm12
 1      3     0.50                        vmulsd	%xmm12, %xmm0, %xmm13
 1      1     0.50           *            vmovsd	%xmm13, 24(%r12,%r13)
 1      10    1.00    *                   vaddsd	32(%r12,%r11), %xmm13, %xmm14
 1      10    1.00    *                   vaddsd	40(%r12,%r13), %xmm14, %xmm15
 1      10    1.00    *                   vaddsd	32(%r12,%r10), %xmm15, %xmm1
 1      3     0.50                        vmulsd	%xmm1, %xmm0, %xmm1
 1      1     0.50           *            vmovsd	%xmm1, 32(%r12,%r13)
 1      1     0.25                        addq	$32, %r12
 1      1     0.25                        cmpq	%rbx, %r15
 1      1     0.25                        jb	..B1.75


Resources:
[0]   - ZnAGU0
[1]   - ZnAGU1
[2]   - ZnALU0
[3]   - ZnALU1
[4]   - ZnALU2
[5]   - ZnALU3
[6]   - ZnDivider
[7]   - ZnFPU0
[8]   - ZnFPU1
[9]   - ZnFPU2
[10]  - ZnFPU3
[11]  - ZnMultiplier


Resource pressure per iteration:
[0]    [1]    [2]    [3]    [4]    [5]    [6]    [7]    [8]    [9]    [10]   [11]   
8.00   8.00   1.00   1.00   1.00   1.00    -     12.00  4.00    -      -      -     

Resource pressure by instruction:
[0]    [1]    [2]    [3]    [4]    [5]    [6]    [7]    [8]    [9]    [10]   [11]   Instructions:
0.98   0.02    -      -      -      -      -      -      -      -      -      -     vmovsd	8(%r12,%r11), %xmm2
 -      -     0.01    -      -     0.99    -      -      -      -      -      -     incq	%r15
0.01   0.99    -      -      -      -      -     1.00    -      -      -      -     vaddsd	16(%r12,%r13), %xmm2, %xmm3
0.99   0.01    -      -      -      -      -     1.00    -      -      -      -     vaddsd	8(%r12,%r10), %xmm3, %xmm4
 -      -      -      -      -      -      -     1.00    -      -      -      -     vaddsd	%xmm1, %xmm4, %xmm1
 -      -      -      -      -      -      -      -     1.00    -      -      -     vmulsd	%xmm1, %xmm0, %xmm5
0.01   0.99    -      -      -      -      -      -      -      -      -      -     vmovsd	%xmm5, 8(%r12,%r13)
0.99   0.01    -      -      -      -      -     1.00    -      -      -      -     vaddsd	16(%r12,%r11), %xmm5, %xmm6
0.99   0.01    -      -      -      -      -     1.00    -      -      -      -     vaddsd	24(%r12,%r13), %xmm6, %xmm7
0.01   0.99    -      -      -      -      -     1.00    -      -      -      -     vaddsd	16(%r12,%r10), %xmm7, %xmm8
 -      -      -      -      -      -      -      -     1.00    -      -      -     vmulsd	%xmm8, %xmm0, %xmm9
0.01   0.99    -      -      -      -      -      -      -      -      -      -     vmovsd	%xmm9, 16(%r12,%r13)
0.99   0.01    -      -      -      -      -     1.00    -      -      -      -     vaddsd	24(%r12,%r11), %xmm9, %xmm10
0.99   0.01    -      -      -      -      -     1.00    -      -      -      -     vaddsd	32(%r12,%r13), %xmm10, %xmm11
0.01   0.99    -      -      -      -      -     1.00    -      -      -      -     vaddsd	24(%r12,%r10), %xmm11, %xmm12
 -      -      -      -      -      -      -      -     1.00    -      -      -     vmulsd	%xmm12, %xmm0, %xmm13
0.01   0.99    -      -      -      -      -      -      -      -      -      -     vmovsd	%xmm13, 24(%r12,%r13)
0.99   0.01    -      -      -      -      -     1.00    -      -      -      -     vaddsd	32(%r12,%r11), %xmm13, %xmm14
0.99   0.01    -      -      -      -      -     1.00    -      -      -      -     vaddsd	40(%r12,%r13), %xmm14, %xmm15
0.01   0.99    -      -      -      -      -     1.00    -      -      -      -     vaddsd	32(%r12,%r10), %xmm15, %xmm1
 -      -      -      -      -      -      -      -     1.00    -      -      -     vmulsd	%xmm1, %xmm0, %xmm1
0.02   0.98    -      -      -      -      -      -      -      -      -      -     vmovsd	%xmm1, 32(%r12,%r13)
 -      -      -      -     1.00    -      -      -      -      -      -      -     addq	$32, %r12
 -      -      -     1.00    -      -      -      -      -      -      -      -     cmpq	%rbx, %r15
 -      -     0.99    -      -     0.01    -      -      -      -      -      -     jb	..B1.75


Timeline view:
                    0123456789          0123456789          0123456789          0123456789          0123456789
Index     0123456789          0123456789          0123456789          0123456789          0123456789          

[0,0]     DeeeeeeeeER    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .   .   vmovsd	8(%r12,%r11), %xmm2
[0,1]     DeE-------R    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .   .   incq	%r15
[0,2]     D====eeeeeeeeeeER   .    .    .    .    .    .    .    .    .    .    .    .    .    .    .    .   .   vaddsd	16(%r12,%r13), %xmm2, %xmm3
[0,3]     D==========eeeeeeeeeeER  .    .    .    .    .    .    .    .    .    .    .    .    .    .    .   .   vaddsd	8(%r12,%r10), %xmm3, %xmm4
[0,4]     .D===================eeeER    .    .    .    .    .    .    .    .    .    .    .    .    .    .   .   vaddsd	%xmm1, %xmm4, %xmm1
[0,5]     .D======================eeeER .    .    .    .    .    .    .    .    .    .    .    .    .    .   .   vmulsd	%xmm1, %xmm0, %xmm5
[0,6]     .D=========================eER.    .    .    .    .    .    .    .    .    .    .    .    .    .   .   vmovsd	%xmm5, 8(%r12,%r13)
[0,7]     .D======================eeeeeeeeeeER    .    .    .    .    .    .    .    .    .    .    .    .   .   vaddsd	16(%r12,%r11), %xmm5, %xmm6
[0,8]     . D===========================eeeeeeeeeeER   .    .    .    .    .    .    .    .    .    .    .   .   vaddsd	24(%r12,%r13), %xmm6, %xmm7
[0,9]     . D=================================eeeeeeeeeeER  .    .    .    .    .    .    .    .    .    .   .   vaddsd	16(%r12,%r10), %xmm7, %xmm8
[0,10]    . D===========================================eeeER    .    .    .    .    .    .    .    .    .   .   vmulsd	%xmm8, %xmm0, %xmm9
[0,11]    . D==============================================eER   .    .    .    .    .    .    .    .    .   .   vmovsd	%xmm9, 16(%r12,%r13)
[0,12]    .  D==========================================eeeeeeeeeeER  .    .    .    .    .    .    .    .   .   vaddsd	24(%r12,%r11), %xmm9, %xmm10
[0,13]    .  D================================================eeeeeeeeeeER .    .    .    .    .    .    .   .   vaddsd	32(%r12,%r13), %xmm10, %xmm11
[0,14]    .  D======================================================eeeeeeeeeeER.    .    .    .    .    .   .   vaddsd	24(%r12,%r10), %xmm11, %xmm12
[0,15]    .  D================================================================eeeER  .    .    .    .    .   .   vmulsd	%xmm12, %xmm0, %xmm13
[0,16]    .   D==================================================================eER .    .    .    .    .   .   vmovsd	%xmm13, 24(%r12,%r13)
[0,17]    .   D===============================================================eeeeeeeeeeER.    .    .    .   .   vaddsd	32(%r12,%r11), %xmm13, %xmm14
[0,18]    .   D=====================================================================eeeeeeeeeeER    .    .   .   vaddsd	40(%r12,%r13), %xmm14, %xmm15
[0,19]    .   D===========================================================================eeeeeeeeeeER   .   .   vaddsd	32(%r12,%r10), %xmm15, %xmm1
[0,20]    .    D====================================================================================eeeER.   .   vmulsd	%xmm1, %xmm0, %xmm1
[0,21]    .    D=======================================================================================eER   .   vmovsd	%xmm1, 32(%r12,%r13)
[0,22]    .    DeE---------------------------------------------------------------------------------------R   .   addq	$32, %r12
[0,23]    .    DeE---------------------------------------------------------------------------------------R   .   cmpq	%rbx, %r15
[0,24]    .    .DeE--------------------------------------------------------------------------------------R   .   jb	..B1.75
[1,0]     .    .DeeeeeeeeE-------------------------------------------------------------------------------R   .   vmovsd	8(%r12,%r11), %xmm2
[1,1]     .    .DeE--------------------------------------------------------------------------------------R   .   incq	%r15
[1,2]     .    .D=====eeeeeeeeeeE------------------------------------------------------------------------R   .   vaddsd	16(%r12,%r13), %xmm2, %xmm3
[1,3]     .    . D==========eeeeeeeeeeE------------------------------------------------------------------R   .   vaddsd	8(%r12,%r10), %xmm3, %xmm4
[1,4]     .    . D=====================================================================================eeeER .   vaddsd	%xmm1, %xmm4, %xmm1


Average Wait times (based on the timeline view):
[0]: Executions
[1]: Average time spent waiting in a scheduler's queue
[2]: Average time spent waiting in a scheduler's queue while ready
[3]: Average time elapsed from WB until retire stage

      [0]    [1]    [2]    [3]
0.     2     1.0    0.5    39.5      vmovsd	8(%r12,%r11), %xmm2
1.     2     1.0    1.0    46.5      incq	%r15
2.     2     5.5    0.5    36.0      vaddsd	16(%r12,%r13), %xmm2, %xmm3
3.     2     11.0   0.0    33.0      vaddsd	8(%r12,%r10), %xmm3, %xmm4
4.     2     53.0   0.0    0.0       vaddsd	%xmm1, %xmm4, %xmm1
5.     1     23.0   0.0    0.0       vmulsd	%xmm1, %xmm0, %xmm5
6.     1     26.0   0.0    0.0       vmovsd	%xmm5, 8(%r12,%r13)
7.     1     23.0   0.0    0.0       vaddsd	16(%r12,%r11), %xmm5, %xmm6
8.     1     28.0   0.0    0.0       vaddsd	24(%r12,%r13), %xmm6, %xmm7
9.     1     34.0   0.0    0.0       vaddsd	16(%r12,%r10), %xmm7, %xmm8
10.    1     44.0   0.0    0.0       vmulsd	%xmm8, %xmm0, %xmm9
11.    1     47.0   0.0    0.0       vmovsd	%xmm9, 16(%r12,%r13)
12.    1     43.0   0.0    0.0       vaddsd	24(%r12,%r11), %xmm9, %xmm10
13.    1     49.0   0.0    0.0       vaddsd	32(%r12,%r13), %xmm10, %xmm11
14.    1     55.0   0.0    0.0       vaddsd	24(%r12,%r10), %xmm11, %xmm12
15.    1     65.0   0.0    0.0       vmulsd	%xmm12, %xmm0, %xmm13
16.    1     67.0   0.0    0.0       vmovsd	%xmm13, 24(%r12,%r13)
17.    1     64.0   0.0    0.0       vaddsd	32(%r12,%r11), %xmm13, %xmm14
18.    1     70.0   0.0    0.0       vaddsd	40(%r12,%r13), %xmm14, %xmm15
19.    1     76.0   0.0    0.0       vaddsd	32(%r12,%r10), %xmm15, %xmm1
20.    1     85.0   0.0    0.0       vmulsd	%xmm1, %xmm0, %xmm1
21.    1     88.0   0.0    0.0       vmovsd	%xmm1, 32(%r12,%r13)
22.    1     1.0    1.0    87.0      addq	$32, %r12
23.    1     1.0    1.0    87.0      cmpq	%rbx, %r15
24.    1     1.0    0.0    86.0      jb	..B1.75
